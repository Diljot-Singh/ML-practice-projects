{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "name": "Model.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMFl+F7L5WRWGPDj2vj4e67",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Diljot-Singh/ML-practice-projects/blob/main/E-SigningLoan/Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p7b1WSJtTwV3"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sn\n",
        "import random\n",
        "import time\n",
        "\n",
        "random.seed(100)\n",
        "\n",
        "### Data Preprocessing ###\n",
        "\n",
        "dataset = pd.read_csv('financial_data.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0A1f5LCquQuX"
      },
      "source": [
        "# Feature Engineering\n",
        "dataset = dataset.drop(columns = ['months_employed'])\n",
        "dataset['personal_account_months'] = (dataset.personal_account_m + (dataset.personal_account_y * 12))\n",
        "dataset[['personal_account_m', 'personal_account_y', 'personal_account_months']].head()\n",
        "dataset = dataset.drop(columns = ['personal_account_m', 'personal_account_y'])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5M4lTTrZuyc0",
        "outputId": "9782fc9e-33be-43cb-d31c-ed5a5faf3685"
      },
      "source": [
        "# One Hot Encoding\n",
        "dataset = pd.get_dummies(dataset,drop_first=True)\n",
        "dataset.columns\n",
        "#dataset = dataset.drop(columns = ['pay_schedule_semi-monthly'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['entry_id', 'age', 'home_owner', 'income', 'years_employed',\n",
              "       'current_address_year', 'has_debt', 'amount_requested', 'risk_score',\n",
              "       'risk_score_2', 'risk_score_3', 'risk_score_4', 'risk_score_5',\n",
              "       'ext_quality_score', 'ext_quality_score_2', 'inquiries_last_month',\n",
              "       'e_signed', 'personal_account_months', 'pay_schedule_monthly',\n",
              "       'pay_schedule_semi-monthly', 'pay_schedule_weekly'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uMqGLuL7vxC7"
      },
      "source": [
        "# Removing extra columns\n",
        "response = dataset[\"e_signed\"]\n",
        "users = dataset['entry_id']\n",
        "dataset = dataset.drop(columns = [\"e_signed\", \"entry_id\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0SDkjyoBv5NY"
      },
      "source": [
        "# Splitting into Train and Test Set\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(dataset,\n",
        "                                                    response,\n",
        "                                                    test_size = 0.2,\n",
        "                                                    random_state = 0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uOFhQbgAv8LQ"
      },
      "source": [
        "# Feature Scaling\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "sc_X = StandardScaler()\n",
        "X_train2 = pd.DataFrame(sc_X.fit_transform(X_train))\n",
        "X_test2 = pd.DataFrame(sc_X.transform(X_test))\n",
        "X_train2.columns = X_train.columns.values\n",
        "X_test2.columns = X_test.columns.values\n",
        "X_train2.index = X_train.index.values\n",
        "X_test2.index = X_test.index.values\n",
        "X_train = X_train2\n",
        "X_test = X_test2\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        },
        "id": "ZyKRgKuPwyg4",
        "outputId": "bf02aed1-0de2-4320-f73e-c37c991fc390"
      },
      "source": [
        "#### Model Building ####\n",
        "### Comparing Models\n",
        "## Logistic Regression\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "classifier = LogisticRegression(random_state = 0, penalty = 'l2')\n",
        "classifier.fit(X_train, y_train)\n",
        "\n",
        "# Predicting Test Set\n",
        "y_pred = classifier.predict(X_test)\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score, precision_score, recall_score\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "prec = precision_score(y_test, y_pred)\n",
        "rec = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "results = pd.DataFrame([['Linear Regression', acc, prec, rec, f1]],\n",
        "               columns = ['Model', 'Accuracy', 'Precision', 'Recall', 'F1 Score'])\n",
        "\n",
        "\n",
        "## SVM (Linear)\n",
        "from sklearn.svm import SVC\n",
        "classifier = SVC(random_state = 0, kernel = 'linear')\n",
        "classifier.fit(X_train, y_train)\n",
        "\n",
        "# Predicting Test Set\n",
        "y_pred = classifier.predict(X_test)\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "prec = precision_score(y_test, y_pred)\n",
        "rec = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "model_results = pd.DataFrame([['SVM (Linear)', acc, prec, rec, f1]],\n",
        "               columns = ['Model', 'Accuracy', 'Precision', 'Recall', 'F1 Score'])\n",
        "\n",
        "results = results.append(model_results, ignore_index = True)\n",
        "\n",
        "\n",
        "## SVM (rbf)\n",
        "from sklearn.svm import SVC\n",
        "classifier = SVC(random_state = 0, kernel = 'rbf')\n",
        "classifier.fit(X_train, y_train)\n",
        "\n",
        "# Predicting Test Set\n",
        "y_pred = classifier.predict(X_test)\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "prec = precision_score(y_test, y_pred)\n",
        "rec = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "model_results = pd.DataFrame([['SVM (RBF)', acc, prec, rec, f1]],\n",
        "               columns = ['Model', 'Accuracy', 'Precision', 'Recall', 'F1 Score'])\n",
        "\n",
        "results = results.append(model_results, ignore_index = True)\n",
        "\n",
        "\n",
        "## Random Forest\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "classifier = RandomForestClassifier(random_state = 0, n_estimators = 100,\n",
        "                                    criterion = 'entropy')\n",
        "classifier.fit(X_train, y_train)\n",
        "\n",
        "# Predicting Test Set\n",
        "y_pred = classifier.predict(X_test)\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "prec = precision_score(y_test, y_pred)\n",
        "rec = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "model_results = pd.DataFrame([['Random Forest (n=100)', acc, prec, rec, f1]],\n",
        "               columns = ['Model', 'Accuracy', 'Precision', 'Recall', 'F1 Score'])\n",
        "\n",
        "results = results.append(model_results, ignore_index = True)\n",
        "\n",
        "\n",
        "## K-fold Cross Validation\n",
        "from sklearn.model_selection import cross_val_score\n",
        "accuracies = cross_val_score(estimator = classifier, X= X_train, y = y_train,\n",
        "                             cv = 10)\n",
        "print(\"Random Forest Classifier Accuracy: %0.2f (+/- %0.2f)\"  % (accuracies.mean(), accuracies.std() * 2))\n",
        "results"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Random Forest Classifier Accuracy: 0.63 (+/- 0.02)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1 Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Linear Regression</td>\n",
              "      <td>0.562256</td>\n",
              "      <td>0.576207</td>\n",
              "      <td>0.705913</td>\n",
              "      <td>0.634499</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>SVM (Linear)</td>\n",
              "      <td>0.568677</td>\n",
              "      <td>0.578068</td>\n",
              "      <td>0.735477</td>\n",
              "      <td>0.647341</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>SVM (RBF)</td>\n",
              "      <td>0.597432</td>\n",
              "      <td>0.611162</td>\n",
              "      <td>0.692946</td>\n",
              "      <td>0.649490</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Random Forest (n=100)</td>\n",
              "      <td>0.626745</td>\n",
              "      <td>0.645066</td>\n",
              "      <td>0.681535</td>\n",
              "      <td>0.662799</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                   Model  Accuracy  Precision    Recall  F1 Score\n",
              "0      Linear Regression  0.562256   0.576207  0.705913  0.634499\n",
              "1           SVM (Linear)  0.568677   0.578068  0.735477  0.647341\n",
              "2              SVM (RBF)  0.597432   0.611162  0.692946  0.649490\n",
              "3  Random Forest (n=100)  0.626745   0.645066  0.681535  0.662799"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "-2Rt8Q8j2zyC",
        "outputId": "506e7001-d1b7-49a8-aeb2-27ca9aaff0bd"
      },
      "source": [
        "### Parameter Tuning\n",
        "# Applying Grid Search\n",
        "\n",
        "# Round 1: Entropy\n",
        "parameters = {\"max_depth\": [3, None],\n",
        "              \"max_features\": [1, 5, 10],\n",
        "              'min_samples_split': [2, 5, 10],\n",
        "              'min_samples_leaf': [1, 5, 10],\n",
        "              \"bootstrap\": [True, False],\n",
        "              \"criterion\": [\"entropy\"]}\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "grid_search = GridSearchCV(estimator = classifier, # Make sure classifier points to the RF model\n",
        "                           param_grid = parameters,\n",
        "                           scoring = \"accuracy\",\n",
        "                           cv = 10,\n",
        "                           n_jobs = -1)\n",
        "\n",
        "t0 = time.time()\n",
        "grid_search = grid_search.fit(X_train, y_train)\n",
        "t1 = time.time()\n",
        "print(\"Took %0.2f seconds\" % (t1 - t0))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Took 4778.20 seconds\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "WOOnDQtY3Iov",
        "outputId": "1b4d8a13-baff-4fd9-af38-efb4b0091ef2"
      },
      "source": [
        "rf_best_accuracy = grid_search.best_score_\n",
        "rf_best_parameters = grid_search.best_params_\n",
        "rf_best_accuracy, rf_best_parameters"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.6362573438541638,\n",
              " {'bootstrap': True,\n",
              "  'criterion': 'entropy',\n",
              "  'max_depth': None,\n",
              "  'max_features': 10,\n",
              "  'min_samples_leaf': 5,\n",
              "  'min_samples_split': 2})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 0
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "uI5_N3QH4aT9",
        "outputId": "84caf1e7-e9d1-440e-99a4-b6a48e215167"
      },
      "source": [
        "# Round 2: Entropy\n",
        "parameters = {\"max_depth\": [None],\n",
        "              \"max_features\": [3, 5, 7],\n",
        "              'min_samples_split': [8, 10, 12],\n",
        "              'min_samples_leaf': [1, 2, 3],\n",
        "              \"bootstrap\": [True],\n",
        "              \"criterion\": [\"entropy\"]}\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "grid_search = GridSearchCV(estimator = classifier, # Make sure classifier points to the RF model\n",
        "                           param_grid = parameters,\n",
        "                           scoring = \"accuracy\",\n",
        "                           cv = 10,\n",
        "                           n_jobs = -1)\n",
        "\n",
        "t0 = time.time()\n",
        "grid_search = grid_search.fit(X_train, y_train)\n",
        "t1 = time.time()\n",
        "print(\"Took %0.2f seconds\" % (t1 - t0))\n",
        "\n",
        "rf_best_accuracy = grid_search.best_score_\n",
        "rf_best_parameters = grid_search.best_params_\n",
        "rf_best_accuracy, rf_best_parameters"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Took 1566.29 seconds\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.6381423801299769,\n",
              " {'bootstrap': True,\n",
              "  'criterion': 'entropy',\n",
              "  'max_depth': None,\n",
              "  'max_features': 7,\n",
              "  'min_samples_leaf': 2,\n",
              "  'min_samples_split': 10})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 0
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "lBUV9-cg4d-7"
      },
      "source": [
        "# Predicting Test Set\n",
        "y_pred = grid_search.predict(X_test)\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "prec = precision_score(y_test, y_pred)\n",
        "rec = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "model_results = pd.DataFrame([['Random Forest (n=100, GSx2 + Entropy)', acc, prec, rec, f1]],\n",
        "               columns = ['Model', 'Accuracy', 'Precision', 'Recall', 'F1 Score'])\n",
        "\n",
        "results = results.append(model_results, ignore_index = True)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "wNfPG51Y4v5R",
        "outputId": "d4a555d7-e9d9-411e-d453-fcbbca333966"
      },
      "source": [
        "# Round 1: Gini\n",
        "parameters = {\"max_depth\": [3, None],\n",
        "              \"max_features\": [1, 5, 10],\n",
        "              'min_samples_split': [2, 5, 10],\n",
        "              'min_samples_leaf': [1, 5, 10],\n",
        "              \"bootstrap\": [True, False],\n",
        "              \"criterion\": [\"gini\"]}\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "grid_search = GridSearchCV(estimator = classifier, # Make sure classifier points to the RF model\n",
        "                           param_grid = parameters,\n",
        "                           scoring = \"accuracy\",\n",
        "                           cv = 10,\n",
        "                           n_jobs = -1)\n",
        "\n",
        "t0 = time.time()\n",
        "grid_search = grid_search.fit(X_train, y_train)\n",
        "t1 = time.time()\n",
        "print(\"Took %0.2f seconds\" % (t1 - t0))\n",
        "\n",
        "rf_best_accuracy = grid_search.best_score_\n",
        "rf_best_parameters = grid_search.best_params_\n",
        "rf_best_accuracy, rf_best_parameters\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Took 2816.23 seconds\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.6368143949287932,\n",
              " {'bootstrap': True,\n",
              "  'criterion': 'gini',\n",
              "  'max_depth': None,\n",
              "  'max_features': 5,\n",
              "  'min_samples_leaf': 1,\n",
              "  'min_samples_split': 10})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 0
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "winbNAcu4zdG"
      },
      "source": [
        "# Round 2: Gini\n",
        "parameters = {\"max_depth\": [None],\n",
        "              \"max_features\": [8, 10, 12],\n",
        "              'min_samples_split': [2, 3, 4],\n",
        "              'min_samples_leaf': [8, 10, 12],\n",
        "              \"bootstrap\": [True],\n",
        "              \"criterion\": [\"gini\"]}\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "grid_search = GridSearchCV(estimator = classifier, # Make sure classifier points to the RF model\n",
        "                           param_grid = parameters,\n",
        "                           scoring = \"accuracy\",\n",
        "                           cv = 10,\n",
        "                           n_jobs = -1)\n",
        "\n",
        "t0 = time.time()\n",
        "grid_search = grid_search.fit(X_train, y_train)\n",
        "t1 = time.time()\n",
        "print(\"Took %0.2f seconds\" % (t1 - t0))\n",
        "\n",
        "rf_best_accuracy = grid_search.best_score_\n",
        "rf_best_parameters = grid_search.best_params_\n",
        "rf_best_accuracy, rf_best_parameters"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Txhq4JrP5sgV"
      },
      "source": [
        "# Predicting Test Set\n",
        "y_pred = grid_search.predict(X_test)\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "prec = precision_score(y_test, y_pred)\n",
        "rec = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "model_results = pd.DataFrame([['Random Forest (n=100, GSx2 + Gini)', acc, prec, rec, f1]],\n",
        "               columns = ['Model', 'Accuracy', 'Precision', 'Recall', 'F1 Score'])\n",
        "\n",
        "results = results.append(model_results, ignore_index = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "sw1-pElZ5yDS"
      },
      "source": [
        "Confusion Matrix\n",
        "cm = confusion_matrix(y_test, y_pred) # rows = truth, cols = prediction\n",
        "df_cm = pd.DataFrame(cm, index = (0, 1), columns = (0, 1))\n",
        "plt.figure(figsize = (10,7))\n",
        "sn.set(font_scale=1.4)\n",
        "sn.heatmap(df_cm, annot=True, fmt='g')\n",
        "print(\"Test Data Accuracy: %0.4f\" % accuracy_score(y_test, y_pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "jcNf6BShSLQR"
      },
      "source": [
        "#### End of Model ####\n",
        "# Formatting Final Results\n",
        "\n",
        "final_results = pd.concat([y_test, users], axis = 1).dropna()\n",
        "final_results['predictions'] = y_pred\n",
        "final_results = final_results[['entry_id', 'e_signed', 'predictions']]"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}